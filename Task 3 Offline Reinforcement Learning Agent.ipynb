{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "141f2ae9-14b5-4f9f-bdb6-cda655674813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Cell 1 — Config\n",
    "# =========================\n",
    "# EITHER: point to Task-1 engineered file (recommended: faster, consistent)\n",
    "USE_CLEAN_FIRST = True\n",
    "CLEAN_PATH = \"loan_clean_subset.csv\"   # upload this if you have it\n",
    "\n",
    "# OR: fall back to raw file (we'll do a minimal preprocess if clean is absent)\n",
    "RAW_PATH = \"accepted_2007_to_2018Q4.csv\"  # upload if needed\n",
    "NROWS_FROM_RAW = 200_000    # None for full data (Colab can handle; start smaller if RAM is tight)\n",
    "\n",
    "RANDOM_STATE = 42\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35c4fe9-a5aa-49f8-af5e-ce3dfd61e4f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b65b041-2193-4904-80ea-d59e6bd8bdd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f4fc399-3bd0-435d-82a8-679473bd78e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: d3rlpy==2.4.0 in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.4.0)\n",
      "Requirement already satisfied: torch>=2.0.0 in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from d3rlpy==2.4.0) (2.9.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from d3rlpy==2.4.0) (4.67.1)\n",
      "Requirement already satisfied: h5py in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from d3rlpy==2.4.0) (3.15.1)\n",
      "Requirement already satisfied: gym>=0.26.0 in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from d3rlpy==2.4.0) (0.26.2)\n",
      "Requirement already satisfied: click in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from d3rlpy==2.4.0) (8.3.0)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from d3rlpy==2.4.0) (4.15.0)\n",
      "Requirement already satisfied: structlog in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from d3rlpy==2.4.0) (25.5.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from d3rlpy==2.4.0) (0.4.6)\n",
      "Requirement already satisfied: dataclasses-json in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from d3rlpy==2.4.0) (0.6.7)\n",
      "Requirement already satisfied: gymnasium in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from d3rlpy==2.4.0) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gym>=0.26.0->d3rlpy==2.4.0) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gym>=0.26.0->d3rlpy==2.4.0) (3.1.1)\n",
      "Requirement already satisfied: gym_notices>=0.0.4 in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gym>=0.26.0->d3rlpy==2.4.0) (0.1.0)\n",
      "Requirement already satisfied: filelock in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->d3rlpy==2.4.0) (3.20.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->d3rlpy==2.4.0) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->d3rlpy==2.4.0) (3.5)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->d3rlpy==2.4.0) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch>=2.0.0->d3rlpy==2.4.0) (2025.9.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch>=2.0.0->d3rlpy==2.4.0) (1.3.0)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json->d3rlpy==2.4.0) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from dataclasses-json->d3rlpy==2.4.0) (0.9.0)\n",
      "Requirement already satisfied: packaging>=17.0 in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json->d3rlpy==2.4.0) (25.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json->d3rlpy==2.4.0) (1.1.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gymnasium->d3rlpy==2.4.0) (0.0.4)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch>=2.0.0->d3rlpy==2.4.0) (3.0.3)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gymnasium==0.29.1 in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gymnasium[classic-control]==0.29.1) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.21.0 in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gymnasium==0.29.1->gymnasium[classic-control]==0.29.1) (1.26.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gymnasium==0.29.1->gymnasium[classic-control]==0.29.1) (3.1.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gymnasium==0.29.1->gymnasium[classic-control]==0.29.1) (4.15.0)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gymnasium==0.29.1->gymnasium[classic-control]==0.29.1) (0.0.4)\n",
      "Requirement already satisfied: pygame>=2.1.3 in c:\\users\\kamya\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from gymnasium[classic-control]==0.29.1) (2.6.1)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "Gym has been unmaintained since 2022 and does not support NumPy 2.0 amongst other critical functionality.\n",
      "Please upgrade to Gymnasium, the maintained drop-in replacement of Gym, or contact the authors of your software and request that they upgrade.\n",
      "Users of this version of Gym should be able to simply replace 'import gym' with 'import gymnasium as gym' in the vast majority of cases.\n",
      "See the migration guide at https://gymnasium.farama.org/introduction/migration_guide/ for additional information.\n",
      "C:\\Users\\kamya\\anaconda3\\envs\\rl-fintech\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 2 — Install & Imports (Fixed)\n",
    "# =========================\n",
    "!pip install -U d3rlpy==2.4.0\n",
    "!pip install -U gymnasium[classic-control]==0.29.1\n",
    "\n",
    "import os, gc, textwrap, numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import d3rlpy\n",
    "from d3rlpy.dataset import MDPDataset\n",
    "from d3rlpy.algos import CQL\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9bb69345-3117-4b57-ae6a-9c451d47899c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================\n",
    "# Cell 3 — Helpers (same mapping as your previous tasks)\n",
    "# =========================\n",
    "DEFAULT_LIKE = {\n",
    "    \"Charged Off\",\"Default\",\n",
    "    \"Late (31-120 days)\",\"Late (16-30 days)\",\n",
    "    \"Does not meet the credit policy. Status:Charged Off\"\n",
    "}\n",
    "PAID_LIKE = {\"Fully Paid\",\"Does not meet the credit policy. Status:Fully Paid\"}\n",
    "\n",
    "def map_target(status: str):\n",
    "    if pd.isna(status): return np.nan\n",
    "    s = str(status).strip()\n",
    "    if s in PAID_LIKE: return 0\n",
    "    if s in DEFAULT_LIKE: return 1\n",
    "    return np.nan\n",
    "\n",
    "def parse_pct(series: pd.Series) -> pd.Series:\n",
    "    return pd.to_numeric(series.astype(str).str.rstrip(\"%\"), errors=\"coerce\")\n",
    "\n",
    "def parse_emp_length(series: pd.Series) -> pd.Series:\n",
    "    def _map(v):\n",
    "        if pd.isna(v): return np.nan\n",
    "        s = str(v).strip().lower()\n",
    "        if s in (\"n/a\",\"na\",\"none\"): return np.nan\n",
    "        if s.startswith(\"<\"): return 0.5\n",
    "        if \"10+\" in s: return 10.0\n",
    "        for tok in s.split():\n",
    "            try: return float(tok)\n",
    "            except: pass\n",
    "        return np.nan\n",
    "    return series.apply(_map)\n",
    "\n",
    "FEATURES_RAW = [\n",
    "    \"loan_amnt\",\"funded_amnt\",\"term\",\"installment\",\"int_rate\",\n",
    "    \"annual_inc\",\"dti\",\"emp_length\",\"home_ownership\",\"verification_status\",\n",
    "    \"purpose\",\"addr_state\",\"revol_bal\",\"revol_util\",\n",
    "    \"open_acc\",\"total_acc\",\"delinq_2yrs\",\"inq_last_6mths\",\"pub_rec\",\n",
    "    \"issue_d\",\"earliest_cr_line\",\"loan_status\"\n",
    "]\n",
    "\n",
    "def add_date_features(frame: pd.DataFrame) -> pd.DataFrame:\n",
    "    X = frame.copy()\n",
    "    if \"issue_d\" in X:\n",
    "        X[\"issue_year\"] = X[\"issue_d\"].dt.year\n",
    "        X[\"issue_month\"] = X[\"issue_d\"].dt.month\n",
    "        X[\"issue_ym\"] = X[\"issue_year\"]*12 + X[\"issue_month\"]\n",
    "    if \"earliest_cr_line\" in X:\n",
    "        if \"issue_d\" in X:\n",
    "            X[\"credit_hist_months\"] = (\n",
    "                (X[\"issue_d\"].dt.year - X[\"earliest_cr_line\"].dt.year)*12 +\n",
    "                (X[\"issue_d\"].dt.month - X[\"earliest_cr_line\"].dt.month)\n",
    "            )\n",
    "        else:\n",
    "            ref = pd.Timestamp(\"2018-12-01\")\n",
    "            X[\"credit_hist_months\"] = (\n",
    "                (ref.year - X[\"earliest_cr_line\"].dt.year)*12 +\n",
    "                (ref.month - X[\"earliest_cr_line\"].dt.month)\n",
    "            )\n",
    "    for d in (\"issue_d\",\"earliest_cr_line\"):\n",
    "        if d in X: X.drop(columns=[d], inplace=True)\n",
    "    return X\n",
    "\n",
    "def robust_time_split(mdf: pd.DataFrame):\n",
    "    # 80/20 by issue_d if feasible; else stratified random\n",
    "    if \"issue_d\" in mdf.columns and mdf[\"issue_d\"].notna().mean() >= 0.7:\n",
    "        temp = mdf[mdf[\"issue_d\"].notna()].copy()\n",
    "        cutoff = temp[\"issue_d\"].quantile(0.80)\n",
    "        train_idx = temp.index[temp[\"issue_d\"] <= cutoff]\n",
    "        test_idx  = temp.index[temp[\"issue_d\"] >  cutoff]\n",
    "        train_df = mdf.loc[train_idx].copy()\n",
    "        test_df  = mdf.loc[test_idx].copy()\n",
    "        # Attach NaT rows to train to avoid empties (ok for this task)\n",
    "        nat_rows = mdf.index[mdf[\"issue_d\"].isna()]\n",
    "        train_df = pd.concat([train_df, mdf.loc[nat_rows]], axis=0)\n",
    "        if len(train_df)>0 and len(test_df)>0 and train_df[\"default\"].nunique()==2:\n",
    "            return train_df, test_df\n",
    "    # Fallback\n",
    "    tr, te = train_test_split(mdf, test_size=0.2, random_state=42, stratify=mdf[\"default\"])\n",
    "    return tr.copy(), te.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d09bfe89-fcf9-4753-bc34-51919253873a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Info] Using clean engineered file: loan_clean_subset.csv\n",
      "Clean file shape: (177016, 24)\n",
      "Train rows: 141612  Test rows: 35404\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loan_amnt</th>\n",
       "      <th>funded_amnt</th>\n",
       "      <th>term</th>\n",
       "      <th>installment</th>\n",
       "      <th>int_rate</th>\n",
       "      <th>annual_inc</th>\n",
       "      <th>dti</th>\n",
       "      <th>emp_length</th>\n",
       "      <th>home_ownership</th>\n",
       "      <th>verification_status</th>\n",
       "      <th>...</th>\n",
       "      <th>revol_util</th>\n",
       "      <th>open_acc</th>\n",
       "      <th>total_acc</th>\n",
       "      <th>delinq_2yrs</th>\n",
       "      <th>inq_last_6mths</th>\n",
       "      <th>pub_rec</th>\n",
       "      <th>issue_year</th>\n",
       "      <th>issue_month</th>\n",
       "      <th>issue_ym</th>\n",
       "      <th>credit_hist_months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>151954</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>10000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>232.64</td>\n",
       "      <td>13.99</td>\n",
       "      <td>25813.22</td>\n",
       "      <td>25.89</td>\n",
       "      <td>9.0</td>\n",
       "      <td>OWN</td>\n",
       "      <td>Verified</td>\n",
       "      <td>...</td>\n",
       "      <td>34.9</td>\n",
       "      <td>10.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>24190</td>\n",
       "      <td>587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127528</th>\n",
       "      <td>35000.0</td>\n",
       "      <td>35000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>808.42</td>\n",
       "      <td>13.67</td>\n",
       "      <td>114000.00</td>\n",
       "      <td>17.28</td>\n",
       "      <td>10.0</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>Verified</td>\n",
       "      <td>...</td>\n",
       "      <td>82.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>24192</td>\n",
       "      <td>261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107844</th>\n",
       "      <td>7275.0</td>\n",
       "      <td>7275.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>250.95</td>\n",
       "      <td>14.65</td>\n",
       "      <td>130000.00</td>\n",
       "      <td>5.35</td>\n",
       "      <td>10.0</td>\n",
       "      <td>RENT</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>...</td>\n",
       "      <td>34.7</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>8</td>\n",
       "      <td>24188</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164311</th>\n",
       "      <td>24000.0</td>\n",
       "      <td>24000.0</td>\n",
       "      <td>36 months</td>\n",
       "      <td>722.76</td>\n",
       "      <td>5.32</td>\n",
       "      <td>108000.00</td>\n",
       "      <td>9.44</td>\n",
       "      <td>3.0</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>Not Verified</td>\n",
       "      <td>...</td>\n",
       "      <td>18.9</td>\n",
       "      <td>13.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>24192</td>\n",
       "      <td>403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59881</th>\n",
       "      <td>22000.0</td>\n",
       "      <td>22000.0</td>\n",
       "      <td>60 months</td>\n",
       "      <td>478.23</td>\n",
       "      <td>10.99</td>\n",
       "      <td>95000.00</td>\n",
       "      <td>10.13</td>\n",
       "      <td>6.0</td>\n",
       "      <td>MORTGAGE</td>\n",
       "      <td>Source Verified</td>\n",
       "      <td>...</td>\n",
       "      <td>82.7</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2015</td>\n",
       "      <td>10</td>\n",
       "      <td>24190</td>\n",
       "      <td>110</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        loan_amnt  funded_amnt        term  installment  int_rate  annual_inc  \\\n",
       "151954    10000.0      10000.0   60 months       232.64     13.99    25813.22   \n",
       "127528    35000.0      35000.0   60 months       808.42     13.67   114000.00   \n",
       "107844     7275.0       7275.0   36 months       250.95     14.65   130000.00   \n",
       "164311    24000.0      24000.0   36 months       722.76      5.32   108000.00   \n",
       "59881     22000.0      22000.0   60 months       478.23     10.99    95000.00   \n",
       "\n",
       "          dti  emp_length home_ownership verification_status  ... revol_util  \\\n",
       "151954  25.89         9.0            OWN            Verified  ...       34.9   \n",
       "127528  17.28        10.0       MORTGAGE            Verified  ...       82.0   \n",
       "107844   5.35        10.0           RENT     Source Verified  ...       34.7   \n",
       "164311   9.44         3.0       MORTGAGE        Not Verified  ...       18.9   \n",
       "59881   10.13         6.0       MORTGAGE     Source Verified  ...       82.7   \n",
       "\n",
       "       open_acc  total_acc  delinq_2yrs  inq_last_6mths  pub_rec  issue_year  \\\n",
       "151954     10.0       19.0          2.0             0.0      0.0        2015   \n",
       "127528     13.0       24.0          0.0             2.0      0.0        2015   \n",
       "107844      5.0       13.0          0.0             0.0      0.0        2015   \n",
       "164311     13.0       36.0          0.0             0.0      0.0        2015   \n",
       "59881       6.0       11.0          0.0             0.0      0.0        2015   \n",
       "\n",
       "        issue_month  issue_ym  credit_hist_months  \n",
       "151954           10     24190                 587  \n",
       "127528           12     24192                 261  \n",
       "107844            8     24188                 119  \n",
       "164311           12     24192                 403  \n",
       "59881            10     24190                 110  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 4 — Load engineered CLEAN file if present; else minimally preprocess RAW\n",
    "# =========================\n",
    "df_clean = None\n",
    "if USE_CLEAN_FIRST and os.path.exists(CLEAN_PATH):\n",
    "    print(\"[Info] Using clean engineered file:\", CLEAN_PATH)\n",
    "    df_clean = pd.read_csv(CLEAN_PATH)\n",
    "    assert \"default\" in df_clean.columns, \"Clean file must contain 'default' column.\"\n",
    "\n",
    "if df_clean is None:\n",
    "    print(\"[Info] CLEAN not found → preprocessing raw:\", RAW_PATH)\n",
    "    hdr = pd.read_csv(RAW_PATH, compression=\"infer\", nrows=0, low_memory=True)\n",
    "    usecols = [c for c in FEATURES_RAW if c in hdr.columns]\n",
    "    df = pd.read_csv(RAW_PATH, compression=\"infer\", usecols=usecols, nrows=NROWS_FROM_RAW, low_memory=True)\n",
    "    print(\"Raw shape:\", df.shape)\n",
    "\n",
    "    if \"int_rate\" in df:   df[\"int_rate\"] = parse_pct(df[\"int_rate\"])\n",
    "    if \"revol_util\" in df: df[\"revol_util\"] = parse_pct(df[\"revol_util\"])\n",
    "    if \"emp_length\" in df: df[\"emp_length\"] = parse_emp_length(df[\"emp_length\"])\n",
    "    for dcol in (\"issue_d\",\"earliest_cr_line\"):\n",
    "        if dcol in df: df[dcol] = pd.to_datetime(df[dcol], format=\"%b-%Y\", errors=\"coerce\")\n",
    "\n",
    "    df[\"default\"] = df[\"loan_status\"].apply(map_target)\n",
    "    df = df[~df[\"default\"].isna()].copy()\n",
    "\n",
    "    # Build modeling frame\n",
    "    keep_cols = [c for c in df.columns if c != \"loan_status\"]\n",
    "    model_df = df[keep_cols].copy()\n",
    "    train_df, test_df = robust_time_split(model_df)\n",
    "\n",
    "    X_train_raw = train_df.drop(columns=[\"default\"])\n",
    "    X_test_raw  = test_df.drop(columns=[\"default\"])\n",
    "    y_train = train_df[\"default\"].astype(int).values\n",
    "    y_test  = test_df[\"default\"].astype(int).values\n",
    "\n",
    "    X_train = add_date_features(X_train_raw)\n",
    "    X_test  = add_date_features(X_test_raw)\n",
    "\n",
    "else:\n",
    "    print(\"Clean file shape:\", df_clean.shape)\n",
    "    X = df_clean.drop(columns=[\"default\"])\n",
    "    y = df_clean[\"default\"].astype(int).values\n",
    "    X_train, X_test, y_train, y_test = train_test_split(\n",
    "        X, y, test_size=0.2, random_state=RANDOM_STATE, stratify=y\n",
    "    )\n",
    "\n",
    "print(\"Train rows:\", len(y_train), \" Test rows:\", len(y_test))\n",
    "display(X_train.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22600e58-bd18-4b66-880c-73e5230b0236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final feature dim: 88\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 5 — Preprocess to numeric arrays (impute, OHE, scale)\n",
    "# =========================\n",
    "num_features = [c for c in X_train.columns if pd.api.types.is_numeric_dtype(X_train[c])]\n",
    "cat_features = [c for c in X_train.columns if not pd.api.types.is_numeric_dtype(X_train[c])]\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n",
    "    (\"onehot\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "preprocess = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, num_features),\n",
    "    (\"cat\", categorical_transformer, cat_features),\n",
    "])\n",
    "\n",
    "X_train_np = preprocess.fit_transform(X_train)\n",
    "X_test_np  = preprocess.transform(X_test)\n",
    "\n",
    "print(\"Final feature dim:\", X_train_np.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bf3f6c0d-f8cd-4eb3-9afd-a45304717242",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-10-29 16:40.23 [info     ] Signatures have been automatically determined. action_signature=Signature(dtype=[dtype('int64')], shape=[(1,)]) observation_signature=Signature(dtype=[dtype('float32')], shape=[(88,)]) reward_signature=Signature(dtype=[dtype('float32')], shape=[(1,)])\n",
      "2025-10-29 16:40.23 [info     ] Action-space has been automatically determined. action_space=<ActionSpace.DISCRETE: 2>\n",
      "2025-10-29 16:40.25 [info     ] Action size has been automatically determined. action_size=2\n",
      "2025-10-29 16:40.30 [info     ] Signatures have been automatically determined. action_signature=Signature(dtype=[dtype('int64')], shape=[(1,)]) observation_signature=Signature(dtype=[dtype('float32')], shape=[(88,)]) reward_signature=Signature(dtype=[dtype('float32')], shape=[(1,)])\n",
      "2025-10-29 16:40.30 [info     ] Action-space has been automatically determined. action_space=<ActionSpace.DISCRETE: 2>\n",
      "2025-10-29 16:40.30 [info     ] Action size has been automatically determined. action_size=2\n",
      "Train transitions: 283,224\n",
      "Test transitions : 70,808\n",
      "Unique train states (applications): 141,612\n",
      "Unique test  states (applications): 35,404\n",
      "obs_train shape: (283224, 88)  actions: (283224,)  rewards: (283224,)  terminals: (283224,)\n",
      "obs_test  shape: (70808, 88)  actions: (70808,)  rewards: (70808,)  terminals: (70808,)\n",
      "train_dataset.size(): 283224\n",
      "test_dataset.size(): 70808\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 6 — Build Offline RL dataset (Contextual bandit augmentation)\n",
    "# =========================\n",
    "# We create one-step transitions for BOTH actions per state:\n",
    "# - action=1 (Approve) → reward depends on outcome\n",
    "# - action=0 (Deny)    → reward = 0\n",
    "#\n",
    "# NOTE: This introduces counterfactual entries for action=0. This is acceptable for this task\n",
    "# to let the agent compare approve vs deny. In production, prefer logged bandit data with IPS/DR.\n",
    "\n",
    "def compute_reward(approve: int, default_flag: int, loan_amnt: float, int_rate: float) -> float:\n",
    "    if approve == 0:\n",
    "        return 0.0\n",
    "    # approve == 1\n",
    "    if default_flag == 0:  # fully paid\n",
    "        return float(loan_amnt) * float(int_rate) / 100.0  # int_rate is a percent value\n",
    "    else:  # defaulted\n",
    "        return -float(loan_amnt)\n",
    "\n",
    "# For rewards we need loan_amnt & int_rate; pull them from ORIGINAL (preprocessed) frames.\n",
    "# If using CLEAN file, those columns should be present. If not, you can add them to the clean pipeline.\n",
    "assert \"loan_amnt\" in X_train.columns and \"int_rate\" in X_train.columns, \\\n",
    "    \"loan_amnt and int_rate must be present in features for the reward function.\"\n",
    "\n",
    "# Build transitions for TRAIN\n",
    "obs_train = []\n",
    "act_train = []\n",
    "rew_train = []\n",
    "ter_train = []\n",
    "\n",
    "for i in range(len(y_train)):\n",
    "    s = X_train_np[i]\n",
    "    la = X_train.iloc[i][\"loan_amnt\"]\n",
    "    ir = X_train.iloc[i][\"int_rate\"]\n",
    "    d  = int(y_train[i])\n",
    "\n",
    "    # action 0 (deny)\n",
    "    obs_train.append(s); act_train.append(0)\n",
    "    rew_train.append(compute_reward(0, d, la, ir)); ter_train.append(1.0)\n",
    "\n",
    "    # action 1 (approve)\n",
    "    obs_train.append(s); act_train.append(1)\n",
    "    rew_train.append(compute_reward(1, d, la, ir)); ter_train.append(1.0)\n",
    "\n",
    "obs_train = np.asarray(obs_train, dtype=np.float32)\n",
    "act_train = np.asarray(act_train, dtype=np.int64)\n",
    "rew_train = np.asarray(rew_train, dtype=np.float32)\n",
    "ter_train = np.asarray(ter_train, dtype=np.float32)\n",
    "\n",
    "train_dataset = MDPDataset(\n",
    "    observations=obs_train,\n",
    "    actions=act_train,\n",
    "    rewards=rew_train,\n",
    "    terminals=ter_train,\n",
    ")\n",
    "\n",
    "# Build transitions for TEST (for evaluation simulation)\n",
    "obs_test = []\n",
    "act_test = []\n",
    "rew_test = []\n",
    "ter_test = []\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    s = X_test_np[i]\n",
    "    la = X_test.iloc[i][\"loan_amnt\"]\n",
    "    ir = X_test.iloc[i][\"int_rate\"]\n",
    "    d  = int(y_test[i])\n",
    "\n",
    "    # Same augmentation to allow greedy eval\n",
    "    obs_test.append(s); act_test.append(0)\n",
    "    rew_test.append(compute_reward(0, d, la, ir)); ter_test.append(1.0)\n",
    "\n",
    "    obs_test.append(s); act_test.append(1)\n",
    "    rew_test.append(compute_reward(1, d, la, ir)); ter_test.append(1.0)\n",
    "\n",
    "obs_test = np.asarray(obs_test, dtype=np.float32)\n",
    "act_test = np.asarray(act_test, dtype=np.int64)\n",
    "rew_test = np.asarray(rew_test, dtype=np.float32)\n",
    "ter_test = np.asarray(ter_test, dtype=np.float32)\n",
    "\n",
    "test_dataset = MDPDataset(\n",
    "    observations=obs_test,\n",
    "    actions=act_test,\n",
    "    rewards=rew_test,\n",
    "    terminals=ter_test,\n",
    ")\n",
    "\n",
    "# --- replace the two print lines in Cell 6 with this block ---\n",
    "\n",
    "n_train = obs_train.shape[0]\n",
    "n_test  = obs_test.shape[0]\n",
    "\n",
    "print(f\"Train transitions: {n_train:,}\")\n",
    "print(f\"Test transitions : {n_test:,}\")\n",
    "\n",
    "# Each state was duplicated with actions {0,1}, so unique states = transitions / 2\n",
    "print(f\"Unique train states (applications): {n_train // 2:,}\")\n",
    "print(f\"Unique test  states (applications): {n_test  // 2:,}\")\n",
    "\n",
    "# Optional extra sanity checks\n",
    "print(\"obs_train shape:\", obs_train.shape, \" actions:\", act_train.shape,\n",
    "      \" rewards:\", rew_train.shape, \" terminals:\", ter_train.shape)\n",
    "print(\"obs_test  shape:\", obs_test.shape,  \" actions:\", act_test.shape,\n",
    "      \" rewards:\", rew_test.shape,  \" terminals:\", ter_test.shape)\n",
    "\n",
    "# If you’re curious whether your d3rlpy version exposes a size method:\n",
    "try:\n",
    "    print(\"train_dataset.size():\", train_dataset.size())\n",
    "    print(\"test_dataset.size():\",  test_dataset.size())\n",
    "except Exception:\n",
    "    pass  # not all versions expose .size()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "678528d4-65bd-45a6-bfc0-4189a9e2e4ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[robust_fit] Trying signature #1 ...\n",
      "[robust_fit] Signature #1 failed: QLearningAlgoBase.fit() got an unexpected keyword argument 'n_epochs'\n",
      "[robust_fit] Trying signature #2 ...\n",
      "[robust_fit] Signature #2 failed: QLearningAlgoBase.fit() got an unexpected keyword argument 'epochs'\n",
      "[robust_fit] Trying signature #3 ...\n",
      "[robust_fit] Signature #3 failed: QLearningAlgoBase.fit() got an unexpected keyword argument 'logdir'\n",
      "[robust_fit] Trying signature #4 ...\n",
      "2025-10-29 16:44.58 [info     ] dataset info                   dataset_info=DatasetInfo(observation_signature=Signature(dtype=[dtype('float32')], shape=[(88,)]), action_signature=Signature(dtype=[dtype('int64')], shape=[(1,)]), reward_signature=Signature(dtype=[dtype('float32')], shape=[(1,)]), action_space=<ActionSpace.DISCRETE: 2>, action_size=2)\n",
      "2025-10-29 16:44.58 [info     ] Directory is created at d3rlpy_logs\\DiscreteCQL_20251029164458\n",
      "2025-10-29 16:44.58 [debug    ] Building models...            \n",
      "2025-10-29 16:44.59 [debug    ] Models have been built.       \n",
      "2025-10-29 16:44.59 [info     ] Parameters                     params={'observation_shape': [88], 'action_size': 2, 'config': {'type': 'discrete_cql', 'params': {'batch_size': 32, 'gamma': 0.99, 'observation_scaler': {'type': 'none', 'params': {}}, 'action_scaler': {'type': 'none', 'params': {}}, 'reward_scaler': {'type': 'none', 'params': {}}, 'learning_rate': 6.25e-05, 'optim_factory': {'type': 'adam', 'params': {'betas': [0.9, 0.999], 'eps': 1e-08, 'weight_decay': 0, 'amsgrad': False}}, 'encoder_factory': {'type': 'default', 'params': {'activation': 'relu', 'use_batch_norm': False, 'dropout_rate': None}}, 'q_func_factory': {'type': 'mean', 'params': {'share_encoder': False}}, 'n_critics': 1, 'target_update_interval': 8000, 'alpha': 1.0}}}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ---- Robust trainer that works across d3rlpy versions ----\n",
    "def robust_fit(algo, dataset, logdir=\"./logs_cql\", verbose=True):\n",
    "    attempts = []\n",
    "\n",
    "    # Most common modern signatures\n",
    "    attempts.append(lambda: algo.fit(dataset, n_epochs=20, logdir=logdir, verbose=verbose))\n",
    "    attempts.append(lambda: algo.fit(dataset, epochs=20, logdir=logdir, verbose=verbose))\n",
    "\n",
    "    # Positional-only epochs (older versions)\n",
    "    attempts.append(lambda: algo.fit(dataset, 20, logdir=logdir, verbose=verbose))\n",
    "    attempts.append(lambda: algo.fit(dataset, 20))\n",
    "\n",
    "    # Step-based training (some versions prefer total gradient steps)\n",
    "    attempts.append(lambda: algo.fit(dataset, n_steps=100_000, logdir=logdir, verbose=verbose))\n",
    "    attempts.append(lambda: algo.fit(dataset, total_steps=100_000, logdir=logdir, verbose=verbose))\n",
    "\n",
    "    # Last resort: minimal call\n",
    "    attempts.append(lambda: algo.fit(dataset))\n",
    "\n",
    "    last_err = None\n",
    "    for i, call in enumerate(attempts, 1):\n",
    "        try:\n",
    "            print(f\"[robust_fit] Trying signature #{i} ...\")\n",
    "            return call()\n",
    "        except TypeError as e:\n",
    "            print(f\"[robust_fit] Signature #{i} failed: {e}\")\n",
    "            last_err = e\n",
    "        except Exception as e:\n",
    "            print(f\"[robust_fit] Signature #{i} failed (other): {e}\")\n",
    "            last_err = e\n",
    "    raise last_err if last_err else RuntimeError(\"All fit() signatures failed.\")\n",
    "\n",
    "# ---- Call the robust trainer ----\n",
    "robust_fit(algo, train_dataset, logdir=\"./logs_cql\", verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68247634-38d9-4299-991f-c534737e39f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg reward per application: -165.57\n",
      "Approval rate: 9.79%\n",
      "Approved & Fully Paid count: 2736\n",
      "Approved & Defaulted count : 731\n",
      "\n",
      "Decision vs Outcome (test):\n",
      "          Paid  Default\n",
      "Deny     25463     6474\n",
      "Approve   2736      731\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 8 — Evaluate policy offline on TEST set\n",
    "# =========================\n",
    "# Greedy action per state: a_hat = argmax_a Q(s,a)\n",
    "# Then compute the realized reward using the ground-truth label and your reward function.\n",
    "\n",
    "def greedy_action(algo: CQL, states: np.ndarray) -> np.ndarray:\n",
    "    # d3rlpy's predict expects batch of observations\n",
    "    return algo.predict(states)\n",
    "\n",
    "# Deduplicate the paired (s, a=0) and (s, a=1) in test_dataset to one unique state list\n",
    "# Since we appended actions in order [0, 1], take every other obs as the unique state.\n",
    "unique_states = obs_test[::2]   # every two entries share the same state\n",
    "assert unique_states.shape[0] == len(y_test)\n",
    "\n",
    "a_hat = greedy_action(algo, unique_states)  # 0 or 1 per state\n",
    "\n",
    "# Compute rewards under your rule using X_test original fields + y_test\n",
    "rewards = []\n",
    "approved_defaults = 0\n",
    "approved_paid = 0\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    la = X_test.iloc[i][\"loan_amnt\"]\n",
    "    ir = X_test.iloc[i][\"int_rate\"]\n",
    "    d  = int(y_test[i])\n",
    "    ah = int(a_hat[i])\n",
    "\n",
    "    r = compute_reward(ah, d, la, ir)\n",
    "    rewards.append(r)\n",
    "\n",
    "    if ah == 1:\n",
    "        if d == 1: approved_defaults += 1\n",
    "        else:      approved_paid += 1\n",
    "\n",
    "rewards = np.array(rewards, dtype=float)\n",
    "\n",
    "avg_reward = rewards.mean()\n",
    "approval_rate = float((a_hat == 1).mean())\n",
    "\n",
    "print(f\"Avg reward per application: {avg_reward:,.2f}\")\n",
    "print(f\"Approval rate: {approval_rate*100:.2f}%\")\n",
    "print(f\"Approved & Fully Paid count: {approved_paid}\")\n",
    "print(f\"Approved & Defaulted count : {approved_defaults}\")\n",
    "\n",
    "# Simple confusion-style table for approvals on test:\n",
    "# rows = model decision (Deny/Approve), cols = outcome (Paid/Default)\n",
    "deny_paid = ((a_hat == 0) & (y_test == 0)).sum()\n",
    "deny_def  = ((a_hat == 0) & (y_test == 1)).sum()\n",
    "app_paid  = ((a_hat == 1) & (y_test == 0)).sum()\n",
    "app_def   = ((a_hat == 1) & (y_test == 1)).sum()\n",
    "\n",
    "print(\"\\nDecision vs Outcome (test):\")\n",
    "print(pd.DataFrame(\n",
    "    [[deny_paid, deny_def],\n",
    "     [app_paid,  app_def]],\n",
    "    index=[\"Deny\",\"Approve\"],\n",
    "    columns=[\"Paid\",\"Default\"]\n",
    "))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f41a9709-d32b-4d3e-b95a-c93f7a01194c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved:\n",
      " - /content/offline_rl_cql\\cql_discrete_model.d3\n",
      " - /content/offline_rl_cql\\preprocess.joblib\n",
      " - /content/offline_rl_cql\\report.txt\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# Cell 9 — Save artifacts (policy + preprocessor) for reuse\n",
    "# =========================\n",
    "ART_DIR = \"/content/offline_rl_cql\"\n",
    "os.makedirs(ART_DIR, exist_ok=True)\n",
    "\n",
    "# Save d3rlpy model\n",
    "algo.save(os.path.join(ART_DIR, \"cql_discrete_model.d3\"))\n",
    "\n",
    "# Save the sklearn preprocess pipeline (so you can serve this policy later)\n",
    "import joblib\n",
    "joblib.dump(preprocess, os.path.join(ART_DIR, \"preprocess.joblib\"))\n",
    "\n",
    "# Save a quick report\n",
    "with open(os.path.join(ART_DIR, \"report.txt\"), \"w\") as f:\n",
    "    f.write(textwrap.dedent(f\"\"\"\n",
    "    Offline RL — CQL (Discrete) — One-step Loan Approval\n",
    "    Date: {datetime.now().strftime('%Y-%m-%d %H:%M')}\n",
    "    Avg reward per application (test): {avg_reward:,.4f}\n",
    "    Approval rate (test)              : {approval_rate*100:.2f}%\n",
    "    Approved & Fully Paid (count)     : {approved_paid}\n",
    "    Approved & Defaulted (count)      : {approved_defaults}\n",
    "    \"\"\").strip())\n",
    "\n",
    "print(\"Saved:\")\n",
    "print(\" -\", os.path.join(ART_DIR, \"cql_discrete_model.d3\"))\n",
    "print(\" -\", os.path.join(ART_DIR, \"preprocess.joblib\"))\n",
    "print(\" -\", os.path.join(ART_DIR, \"report.txt\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51733b4-988f-4f7c-8136-82a14a3147e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11 (rl-fintech)",
   "language": "python",
   "name": "rl-fintech"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
